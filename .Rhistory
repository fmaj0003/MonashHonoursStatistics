<<<<<<< Updated upstream
library(tufte)
options(digits = 3)
=======
>>>>>>> Stashed changes
library(haven)
library(data.table)
library(JWileymisc)
library(ggplot2)
library(ggpubr)
library(visreg)
<<<<<<< Updated upstream
library(survey)
## read in data
db <- as.data.table(read_sav("[2021] PSY4210 BL.sav")) # baseline
## if you have saved your last db datafile as an RData, simply go
## to the files tab on the bottom right corner of your window and
## click on it to load your saved db datafile here
## compute a stress variable if you haven't already
db [, PSS2 := 6- PSS2r]
db [, PSS3 := 6- PSS3r]
db[, stress := rowMeans(.SD, na.rm = TRUE),
.SDcols = c("PSS1", "PSS2", "PSS3", "PSS4")]
## compute a self-esteem variable if you haven't already
db[, selfesteem:= rowMeans(.SD, na.rm = TRUE),
.SDcols = c("LSE1", "LSE2", "LSE3", "LSE4")]
## compute a neuroticism variable if you haven't already
db [, N1 := 6- BFI_N1r]
db[, neuroticism:= rowMeans(.SD, na.rm = TRUE),
.SDcols = c("N1", "BFI_N2")]
## create some binary variables
db[, StressHigh := as.integer(stress >= 2.5)]
db[, SelfesteemHigh := as.integer(selfesteem >= 3.75)]
## read in some example data from the internet
## (requires internet connection to run)
dcount <- fread("https://stats.idre.ucla.edu/stat/data/poisson_sim.csv")
plot(testDistribution(dcount$num_awards))
plot(testDistribution(dcount$num_awards, distr = "poisson"))
plotdat <- data.table(x = 0:20)
plotdat[, Lambda1  := dpois(x, lambda = 1)]
plotdat[, Lambda3  := dpois(x, lambda = 3)]
plotdat[, Lambda5  := dpois(x, lambda = 5)]
plotdat[, Lambda10 := dpois(x, lambda = 10)]
ggplot(melt(plotdat, id.vars = "x"), aes(x, value, fill = variable)) +
geom_bar(stat = "identity", position = "dodge") +
theme_pubr() +
xlab("x") +
ylab("Density of the poisson distribution") +
scale_fill_discrete("")
tmp <- data.frame(lambda = seq(from = .05, to = 10, by = .05))
ggplot(tmp, aes(lambda, lambda)) +
geom_point() +
theme_pubr()
ggplot(tmp, aes(lambda, log(lambda))) +
geom_point() +
theme_pubr()
tmp2 <- data.frame(eta = seq(from = -5, to = 5, by = .1))
ggplot(tmp2, aes(eta, eta)) +
geom_point() +
theme_pubr()
ggplot(tmp2, aes(eta, exp(eta))) +
geom_point() +
theme_pubr()
m <- glm(num_awards ~ math, data = dcount, family = poisson())
plot(testDistribution(dcount$num_awards, distr = "poisson"))
summary(m)
visreg(m, xvar = "math", partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted log number of awards") +
theme_pubr()
exp(coef(m))
exp(confint(m))
visreg(m, xvar = "math", scale = "response",
partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted number of awards") +
theme_pubr()
tmp <- data.frame(mu = seq(from = .01, to = .99, by = .01))
ggplot(tmp, aes(mu, mu)) +
geom_point() +
theme_pubr()
ggplot(tmp, aes(mu, mu/(1 - mu))) +
geom_point() +
theme_pubr()
ggplot(tmp, aes(mu, log(mu/(1 - mu)))) +
geom_point() +
theme_pubr()
tmp2 <- data.frame(eta = seq(from = -5, to = 5, by = .1))
ggplot(tmp2, aes(eta, eta)) +
geom_point() +
theme_pubr()
ggplot(tmp2, aes(eta, 1/(1 + exp(-eta)))) +
geom_point() +
theme_pubr()
egltable(
c("StressHigh", "stress", "SelfesteemHigh", "selfesteem"),
data = db, strict=FALSE)
egltable(
c("stress", "SelfesteemHigh", "selfesteem"),
g = "StressHigh",
data = db, strict=FALSE)
mlog <- glm(StressHigh ~ SelfesteemHigh, data = db, family = binomial())
summary(mlog)
visreg(mlog, xvar = "SelfesteemHigh", partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted log odds of high stress") +
theme_pubr()
exp(coef(mlog))
exp(confint(mlog))
visreg(mlog, xvar = "SelfesteemHigh", scale = "response",
partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted probability of being high stress") +
theme_pubr()
mlog2 <- glm(StressHigh ~ selfesteem, data = db, family = binomial())
summary(mlog2)
exp(coef(mlog2))
exp(confint(mlog2))
visreg(mlog2, xvar = "selfesteem", scale = "response",
partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted probability of being high stress") +
theme_pubr()
accdata <- data.table(
Observed = db$StressHigh,
Predicted = as.integer(predict(mlog2, type = "response") >= .50))
## quick view of the data
head(accdata)
## simple frequencies table
xtabs(~ Observed + Predicted, data = accdata)
## accuracy is the average number of times predictions match observed
mean(accdata$Observed == accdata$Predicted)
newdata <- data.table(
selfesteem = c(1, 2, 3, 4))
newdata$Prob <- predict(mlog2,
newdata = newdata,
type = "response")
knitr::kable(newdata)
visreg(mlog3, xvar = "selfesteem",
by = "neuroticism", breaks = c(3, 4.5),
scale = "response", overlay = TRUE,
partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted probability of being high stress") +
theme_pubr()
mlog3 <- glm(StressHigh ~ selfesteem + neuroticism,
data = db, family = binomial())
summary(mlog3)
visreg(mlog3, xvar = "selfesteem",
by = "neuroticism", breaks = c(3, 4.5),
scale = "linear", overlay = TRUE,
partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted log odds of being high stress") +
theme_pubr()
visreg(mlog3, xvar = "selfesteem",
by = "neuroticism", breaks = c(3, 4.5),
scale = "response", overlay = TRUE,
partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted probability of being high stress") +
theme_pubr()
exp(coef(m))
exp(confint(m))
visreg(m, xvar = "prog", partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted log nummber of awards") +
theme_pubr()
## Plot the distribution of the outcome num_awards:
plot(testDistribution(dcount$num_awards, distr = "poisson"))
## fit poisson regression num_awards on prog:
#m <- glm(num_awards ~ math, data = dcount, family = poisson())
m <- glm(num_awards ~ math, data = dcount, family = poisson())
## Show the results:
summary(m)
## calculate IRRs and confidence intervals on the IRR scale:
exp(coef(m))
exp(confint(m))
visreg(m, xvar = "prog", partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted log nummber of awards") +
theme_pubr()
library(haven)
library(data.table)
library(JWileymisc)
library(ggplot2)
library(ggpubr)
library(visreg)
library(survey)
dcount <- fread("https://stats.idre.ucla.edu/stat/data/poisson_sim.csv")
### 1. Poisson ###
# Fit a poisson regression predicting the number of awards,
# `num_awards` from `prog` in the `dcount` data. Try to
# interpret the results using IRRs and make a graph.
# Note: "There is no association between prog and num_awards so
# do not be surprised if the graphs etc are not that interesting.")
## Plot the distribution of the outcome num_awards:
plot(testDistribution(dcount$num_awards, distr = "poisson"))
## fit poisson regression num_awards on prog:
#m <- glm(num_awards ~ math, data = dcount, family = poisson())
m <- glm(num_awards ~ math, data = dcount, family = poisson())
## Show the results:
summary(m)
## calculate IRRs and confidence intervals on the IRR scale:
exp(coef(m))
exp(confint(m))
visreg(m, xvar = "prog", partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted log nummber of awards") +
theme_pubr()
View(m)
m <- glm(num_awards ~ prog, data = dcount, family = poisson())
summary(m)
exp(coef(m))
exp(confint(m))
visreg(m, xvar = "prog", partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted log nummber of awards") +
theme_pubr()
visreg(m, xvar = "prog", response,
partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted number of awarrds") +
theme_pubr()
exp(coef(m))
exp(confint(m))
summary(m)
exp(coef(m))
exp(confint(m))
set.seed(666) #this is so that the fake-data generated is the same as michelle's
dcount$unicorn <- sample(0:1, size = nrow(dcount), replace = TRUE)
mlog <- glm(unicorn ~ math, data = dcount, family = binomial())
summary(mlog)
exp(coef(mlog))
exp(confint(mlog))
h <- .01
## make the original dataset
originaldata <- dcount[, .(math)]
## make the increased self esteem dataset (selfesteem + h)
increaseddata <- dcount[, .(math = math + h)]
## calculate original predicted probabilities
originaldata$Prob <- predict(mlog, newdata = originaldata,
type = "reponse")
## calculate the difference in probabilities per unit
diffprob <- increaseddata$Prob - originaldata$Prob / h
mean(diffprob)
h <- .01
originaldata <- dcount[, .(math)]
increaseddata <- dcount[, .(math = math + h)]
originaldata$Prob <- predict(mlog, newdata = originaldata,
increaseddata$Prob <- predict(mlong, newdata = increaseddata,
type = "response")
diffprob <- increaseddata$Prob - originaldata$Prob / h
diffprob <- increaseddata$Prob - originaldata$Prob / h
mean(diffprob)
exp(coef(m))
exp(confint(m))
summary(m)
diffprob <- increaseddata$Prob - originaldata$Prob / h
mean(diffprob)
increaseddata$Prob <- predict(mlong, newdata = increaseddata,
type = "response")
increaseddata$Prob <- predict(mlog, newdata = increaseddata,
type = "response")
diffprob <- increaseddata$Prob - originaldata$Prob / h
mean(diffprob)
diffprob <- increaseddata$Prob - originaldata$Prob / h
mean(diffprob)
exp(coef(m))
exp(confint(m))
summary(m)
diffprob <- (increaseddata$Prob - originaldata$Prob) / h
mean(diffprob)
View(dcount)
View(mlog)
## calculate the average marginal effect
mean(diffprob)
## pick h value for difference, store that in variable h
h <- .01
originaldata <- dcount[, .(math)]
increaseddata <- dcount[, .(math = math + h)]
originaldata$Prob <- predict(mlog, newdata = originaldata,
type = "reponse")
increaseddata$Prob <- predict(mlog, newdata = increaseddata,
type = "response")
originaldata$Prob <- predict(mlog, newdata = originaldata,
type = "reponse")
?predict
View(mlog)
summary(mlog)
h <- .01
originaldata <- dcount[, .(math)]
increaseddata <- dcount[, .(math = math + h)]
originaldata$Prob <- predict(mlog, newdata = originaldata,
originaldata$Prob <- predict(mlog, newdata = originaldata,
type = "reponse")
increaseddata$Prob <- predict(mlog, newdata = increaseddata,
originaldata$Prob <- predict(mlog, newdata = originaldata,
type = "response")
increaseddata$Prob <- predict(mlog, newdata = increaseddata,
type = "response")
diffprob <- (increaseddata$Prob - originaldata$Prob) / h
mean(diffprob)
library(haven)
library(data.table)
library(JWileymisc)
library(ggplot2)
library(ggpubr)
library(visreg)
library(survey)
library(haven)
library(data.table)
library(JWileymisc)
library(ggplot2)
library(ggpubr)
library(visreg)
library(survey)
dcount <- fread("https://stats.idre.ucla.edu/stat/data/poisson_sim.csv")
q()
library(haven)
library(data.table)
library(JWileymisc)
library(ggplot2)
library(ggpubr)
library(visreg)
library(survey)
dcount <- fread("https://stats.idre.ucla.edu/stat/data/poisson_sim.csv")
plot(testDistribution(dcount$num_awards, distr = "poisson"))
m <- glm(num_awards ~ prog, data = dcount, family = poisson())
summary(m)
exp(coef(m))
exp(confint(m))
visreg(m, xvar = "prog", partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted log nummber of awards") +
theme_pubr()
visreg(m, xvar = "prog", response,
partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted number of awarrds") +
theme_pubr()
visreg(m, xvar = "prog", response,
partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted number of awarrds") +
theme_pubr()
exp(coef(m))
exp(confint(m))
set.seed(666) #this is so that the fake-data generated is the same as michelle's
dcount$unicorn <- sample(0:1, size = nrow(dcount), replace = TRUE)
View(dcount)
mlog <- glm(unicorn ~ math, data = dcount, family = binomial())
summary(mlog)
exp(coef(mlog))
exp(confint(mlog))
?visreg
visreg(m, xvar = "prog", scale = response,
partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted number of awards") +
theme_pubr()
visreg(m, xvar = "prog", scale = "response",
partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted number of awards") +
theme_pubr()
visreg(m, xvar = "prog",
partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted log nummber of awards") +
theme_pubr()
visreg(m, xvar = "prog", scale = "response",
partial = FALSE, rug = FALSE, gg = TRUE) +
ylab("predicted number of awards") +
theme_pubr()
h <- .01
## make the original dataset
originaldata <- dcount[, .(math)]
## make the increased self esteem dataset (selfesteem + h)
increaseddata <- dcount[, .(math = math + h)]
## calculate original predicted probabilities
originaldata$Prob <- predict(mlog, newdata = originaldata,
type = "response")
## calculate increased predicted probabilities
increaseddata$Prob <- predict(mlog, newdata = increaseddata,
type = "response")
## calculate the difference in probabilities per unit
diffprob <- (increaseddata$Prob - originaldata$Prob) / h
## calculate the average marginal effect
mean(diffprob)
library(haven)
library(data.table)
library(JWileymisc)
library(ggplot2)
library(ggpubr)
library(visreg)
setwd("~/git_repos/MonashHonoursStatistics")
library(haven)
library(data.table)
library(JWileymisc)
library(ggplot2)
library(ggpubr)
library(visreg)
db <- as.data.table(read_sav("[2021] PSY4210 BL.sav")) # baseline
db[, SE := rowMeans(.SD, na.rm = TRUE) * 4,
.SDcols = c("LSE1", "LSE2", "LSE3", "LSE4")]
db [, PSS2 := 6- PSS2r]
db [, PSS3 := 6- PSS3r]
db[, Stress := rowMeans(.SD, na.rm = TRUE) * 4,
.SDcols = c("PSS1", "PSS2", "PSS3", "PSS4")]
m <- lm(SE ~ Stress, data = db)
summary(m)
confint(m)
visreg(m, xvar = "Stress", partial = FALSE, rug = FALSE, gg = TRUE) +
theme_pubr() +
annotate("text", x = 15, y = 8, label = "b = -0.77, p < .001", size = 4) +
ggtitle("Linear regression of stress of self-esteem",
subtitle = "Shaded region shows 95% confidence interval.")
m_diag <- modelDiagnostics(m, ev.perc = .005)
plot(m_diag, ncol = 2, ask = FALSE)
m_test <- modelTest(m)
knitr::kable(APAStyler(m_test))
library(haven)
library(data.table)
library(JWileymisc)
library(ggplot2)
library(ggpubr)
library(visreg)
## read in data
db <- as.data.table(read_sav("[2021] PSY4210 BL.sav")) # baseline
ggplot() +
geom_hline(yintercept = 0, linetype = 3) +
geom_vline(xintercept = 0, linetype = 3) +
geom_abline(intercept = 0, slope = 0.5) +
scale_x_continuous("x (predictor/explanatory variable)",
breaks = c(-3, -2, -1, 0, 1, 2, 3)) +
scale_y_continuous("y (outcome variable)",
breaks = c(-1.5, -1, -0.5, 0, 0.5, 1, 1.5)) +
coord_cartesian(xlim = c(-3, 3),
ylim = c(-1.5, 1.5)) +
theme_pubr() +
annotate("point", x = 0, y = 0, colour = "black") +
annotate("text", x = -.1, y = .1, label = "b[0]", parse = TRUE) +
annotate("segment", x = 0, xend = 1, y = 0, yend = 0, colour = "blue") +
annotate("segment", x = 1, xend = 1, y = 0, yend = 0.5, colour = "blue") +
annotate("text", x = 1.1, y = 0.25, label = "b[1]", parse = TRUE, colour = "blue")
ggplot() +
geom_hline(yintercept = 0, linetype = 3) +
geom_vline(xintercept = 0, linetype = 3) +
geom_abline(intercept = 0, slope = 0.5) +
scale_x_continuous("x (predictor/explanatory variable)",
breaks = c(-3, -2, -1, 0, 1, 2, 3)) +
scale_y_continuous("y (outcome variable)",
breaks = c(-1.5, -1, -0.5, 0, 0.5, 1, 1.5)) +
coord_cartesian(xlim = c(-3, 3),
ylim = c(-1.5, 1.5)) +
theme_pubr() +
annotate("point", x = 0, y = 0, colour = "black") +
annotate("text", x = -.1, y = .1, label = "b[0]", parse = TRUE) +
annotate("segment", x = 0, xend = 1, y = 0, yend = 0, colour = "blue") +
annotate("segment", x = 1, xend = 1, y = 0, yend = 0.5, colour = "blue") +
annotate("text", x = 1.1, y = 0.25, label = "b[1]", parse = TRUE, colour = "blue")
library(haven)
library(data.table)
library(JWileymisc)
library(ggplot2)
library(ggpubr)
library(visreg)
## read in data
db <- as.data.table(read_sav("[2021] PSY4210 BL.sav")) # baseline
m <- lm(neuroticism ~ stress, data = db)
## this package only used for demo purposes - you do NOT need to know or
# understand the code below but it IS fun to play with
library(plotly)
# calculate selfesteem
db[, selfesteem := rowMeans(.SD, na.rm = TRUE) * 4,
.SDcols = c("LSE1", "LSE2", "LSE3", "LSE4")]
# calculate stress
db [, PSS2 := 6- PSS2r]
db [, PSS3 := 6- PSS3r]
db[, stress := rowMeans(.SD, na.rm = TRUE) * 4,
.SDcols = c("PSS1", "PSS2", "PSS3", "PSS4")]
# calculate neuroticism
db [, BFI_N1 := 6- BFI_N1r]
db[, neuroticism := rowMeans(.SD, na.rm = TRUE) * 2,
.SDcols = c("BFI_N1", "BFI_N2")]
# linear model
m <- lm(neuroticism ~ stress + selfesteem, data = db)
stress <- seq(from = min(db$stress, na.rm=TRUE), to = max(db$stress, na.rm=TRUE),
length.out = 100)
selfesteem <- seq(from = min(db$selfesteem, na.rm=TRUE), to = max(db$selfesteem, na.rm=TRUE),
length.out = 100)
neuroticism <- expand.grid(stress = stress, selfesteem = selfesteem)
neuroticism$neuroticism <- predict(m, newdata = -1*neuroticism)
neuroticism <- as.matrix(
reshape(neuroticism, v.names = "neuroticism", timevar = "selfesteem",
idvar = "stress", direction = "wide")[, -1])
plot_ly(x = ~ stress, y = ~ selfesteem, z = ~ neuroticism) %>% add_surface()
ggplot(data.frame(x = seq(-4, 4, by = .05)), aes(x)) +
stat_function(fun = dnorm, args = list(mean = 0, sd = 2),
colour = "blue", size = 1) +
stat_function(fun = dnorm, args = list(mean = 0, sd = 1),
colour = "black", size = 1) +
stat_function(fun = dnorm, args = list(mean = 0, sd = 0.5),
colour = "red", size = 1) +
stat_function(fun = dnorm, args = list(mean = 1, sd = 0.5),
colour = "green", size = 1) +
theme_pubr() +
xlab("x") + ylab("Density of the normal distribution")
m <- lm(neuroticism ~ stress, data = db)
summary(m)
confint(m)
visreg(m, xvar = "stress", gg = TRUE) +
theme_pubr()
visreg(m, xvar = "stress", partial = FALSE, rug = FALSE, gg = TRUE) +
theme_pubr() +
ggtitle("Linear regression of neuroticism on stress",
subtitle = "Shaded region shows 95% confidence interval.")
visreg(m, xvar = "stress", partial = FALSE, rug = FALSE, gg = TRUE) +
theme_pubr() +
annotate("text", x = 15, y = 8, label = "b = 0.XX, p < .0001", size = 4) +
ggtitle("Linear regression of neuroticism on stress",
subtitle = "Shaded region shows 95% confidence interval.")
# Can you fill in the b coefficient in the label from the summary of m above?
malt2 <- lm(log(selfesteem) ~ stress, data = db)
## assess model diagnostics
malt2d <- modelDiagnostics(malt2, ev.perc = .005)
plot(malt2d, ncol = 2, ask = FALSE)
malt2d$extremeValues
malt3 <- lm(log(selfesteem) ~ stress,
data = db[-malt2d$extremeValues$Index])
## assess model diagnostics
malt3d <- modelDiagnostics(malt3, ev.perc = .005)
plot(malt3d, ncol = 2, ask = FALSE)
q()
=======
## read in data
db <- as.data.table(read_sav("[2021] PSY4210 BL.sav")) # baseline data
View(db)
?lm
View(db)
####### WEEK 6 WORKSHEET - missing data #######
library(data.table)
library(JWileymisc)
library(mice)
library(VIM)
dd <- as.data.table(???("???"))
q()
options(digits = 2)
## There are two new packages: (1) mice (2) VIM
## both are used for missing data.
## some people have reported also needing the zip pkg
# install.packages("zip") before the other packages install correctly
library(data.table)
library(JWileymisc)
library(mice)
library(VIM)
---
title: "Missing Data"
install.packages("zip")
library(data.table)
library(JWileymisc)
library(mice)
library(VIM)
install.packages("zip")
install.packages("VIM")
library(data.table)
library(JWileymisc)
library(mice)
library(VIM)
q()
options(digits = 2)
## There are two new packages: (1) mice (2) VIM
## both are used for missing data.
## some people have reported also needing the zip pkg
# install.packages("zip") before the other packages install correctly
library(data.table)
library(JWileymisc)
library(mice)
library(VIM)
options(digits = 2)
## There are two new packages: (1) mice (2) VIM
## both are used for missing data.
## some people have reported also needing the zip pkg
# install.packages("zip") before the other packages install correctly
install.packages("zip")
install.packages("VIM")
library(data.table)
library(JWileymisc)
library(mice)
library(VIM)
library(VIM)
install.packages("ranger")
library(data.table)
library(JWileymisc)
library(mice)
library(VIM)
install.packages("zip")
install.packages("VIM")
install.packages("ranger")
>>>>>>> Stashed changes
